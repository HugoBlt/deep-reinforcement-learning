{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPEN-AI Taxi-V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Episode 20000/20000 || Best average reward 8.749\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from agent import Agent\n",
    "from monitor import interact\n",
    "import gym\n",
    "import numpy as np\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "num_episodes = 20000\n",
    "env = gym.make('Taxi-v3')\n",
    "agent = Agent(epsilon=0.1, epsilon_divisor = 2.0,alpha=0.1, gamma=0.9)\n",
    "avg_rewards, best_avg_reward = interact(env, agent, num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interact_wrapper(epsilon, epsilon_divisor, alpha, gamma):\n",
    "    agent = Agent(epsilon=epsilon, epsilon_divisor = epsilon_divisor,alpha=alpha, gamma=gamma)\n",
    "    avg_rewards, best_avg_reward = interact(env, agent, num_episodes)\n",
    "    return best_avg_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   |  epsilon  | epsilo... |   gamma   |\n",
      "-------------------------------------------------------------------------\n",
      "Episode 20000/20000 || Best average reward 8.893\n",
      "\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 8.89    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.9     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.783\n",
      "\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 8.78    \u001b[0m | \u001b[0m 0.201   \u001b[0m | \u001b[0m 0.00977 \u001b[0m | \u001b[0m 36.71   \u001b[0m | \u001b[0m 0.4163  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.853\n",
      "\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 8.85    \u001b[0m | \u001b[0m 0.7298  \u001b[0m | \u001b[0m 0.008196\u001b[0m | \u001b[0m 32.63   \u001b[0m | \u001b[0m 0.4731  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.695\n",
      "\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 8.69    \u001b[0m | \u001b[0m 0.7284  \u001b[0m | \u001b[0m 0.00322 \u001b[0m | \u001b[0m 13.54   \u001b[0m | \u001b[0m 0.1216  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.594\n",
      "\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 8.59    \u001b[0m | \u001b[0m 0.1879  \u001b[0m | \u001b[0m 0.003704\u001b[0m | \u001b[0m 32.4    \u001b[0m | \u001b[0m 0.39    \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.788\n",
      "\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 8.78    \u001b[0m | \u001b[0m 0.2651  \u001b[0m | \u001b[0m 0.009255\u001b[0m | \u001b[0m 14.28   \u001b[0m | \u001b[0m 0.3462  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.879\n",
      "\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 8.8     \u001b[0m | \u001b[0m 0.9466  \u001b[0m | \u001b[0m 0.001248\u001b[0m | \u001b[0m 23.62   \u001b[0m | \u001b[0m 0.9295  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.837\n",
      "\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 8.83    \u001b[0m | \u001b[0m 0.6654  \u001b[0m | \u001b[0m 0.007147\u001b[0m | \u001b[0m 8.451   \u001b[0m | \u001b[0m 0.9363  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.763\n",
      "\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 8.76    \u001b[0m | \u001b[0m 0.1772  \u001b[0m | \u001b[0m 0.006924\u001b[0m | \u001b[0m 49.13   \u001b[0m | \u001b[0m 0.986   \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.645\n",
      "\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 8.64    \u001b[0m | \u001b[0m 0.8426  \u001b[0m | \u001b[0m 0.002641\u001b[0m | \u001b[0m 26.2    \u001b[0m | \u001b[0m 0.4473  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.784\n",
      "\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 8.78    \u001b[0m | \u001b[0m 0.7303  \u001b[0m | \u001b[0m 0.009075\u001b[0m | \u001b[0m 49.74   \u001b[0m | \u001b[0m 0.7024  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.756\n",
      "\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 8.75    \u001b[0m | \u001b[0m 0.3991  \u001b[0m | \u001b[0m 0.002051\u001b[0m | \u001b[0m 14.74   \u001b[0m | \u001b[0m 0.5514  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.855\n",
      "\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 8.85    \u001b[0m | \u001b[0m 0.92    \u001b[0m | \u001b[0m 0.003814\u001b[0m | \u001b[0m 5.645   \u001b[0m | \u001b[0m 0.1531  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.912\n",
      "\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m 8.91    \u001b[0m | \u001b[95m 0.5592  \u001b[0m | \u001b[95m 0.002123\u001b[0m | \u001b[95m 17.56   \u001b[0m | \u001b[95m 0.5086  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.866\n",
      "\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 8.86    \u001b[0m | \u001b[0m 0.8229  \u001b[0m | \u001b[0m 0.001155\u001b[0m | \u001b[0m 29.47   \u001b[0m | \u001b[0m 0.4244  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.941\n",
      "\n",
      "| \u001b[95m 16      \u001b[0m | \u001b[95m 8.94    \u001b[0m | \u001b[95m 0.3611  \u001b[0m | \u001b[95m 0.006207\u001b[0m | \u001b[95m 21.41   \u001b[0m | \u001b[95m 0.5656  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.759\n",
      "\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 8.75    \u001b[0m | \u001b[0m 0.2685  \u001b[0m | \u001b[0m 0.002605\u001b[0m | \u001b[0m 17.65   \u001b[0m | \u001b[0m 0.3152  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.956\n",
      "\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m 8.95    \u001b[0m | \u001b[95m 0.2767  \u001b[0m | \u001b[95m 0.00832 \u001b[0m | \u001b[95m 34.24   \u001b[0m | \u001b[95m 0.4007  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.721\n",
      "\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 8.72    \u001b[0m | \u001b[0m 0.7483  \u001b[0m | \u001b[0m 0.002227\u001b[0m | \u001b[0m 27.73   \u001b[0m | \u001b[0m 0.1792  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 9.055\n",
      "\n",
      "| \u001b[95m 20      \u001b[0m | \u001b[95m 9.05    \u001b[0m | \u001b[95m 0.1866  \u001b[0m | \u001b[95m 0.003629\u001b[0m | \u001b[95m 23.22   \u001b[0m | \u001b[95m 0.4981  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.926\n",
      "\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 8.92    \u001b[0m | \u001b[0m 0.2628  \u001b[0m | \u001b[0m 0.006948\u001b[0m | \u001b[0m 43.94   \u001b[0m | \u001b[0m 0.9577  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.658\n",
      "\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 8.65    \u001b[0m | \u001b[0m 0.9386  \u001b[0m | \u001b[0m 0.001004\u001b[0m | \u001b[0m 20.48   \u001b[0m | \u001b[0m 0.5296  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.884\n",
      "\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 8.88    \u001b[0m | \u001b[0m 0.6341  \u001b[0m | \u001b[0m 0.008446\u001b[0m | \u001b[0m 3.833   \u001b[0m | \u001b[0m 0.9069  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.865\n",
      "\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 8.86    \u001b[0m | \u001b[0m 0.2122  \u001b[0m | \u001b[0m 0.00188 \u001b[0m | \u001b[0m 49.81   \u001b[0m | \u001b[0m 0.416   \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 9.125\n",
      "\n",
      "| \u001b[95m 25      \u001b[0m | \u001b[95m 9.12    \u001b[0m | \u001b[95m 0.8415  \u001b[0m | \u001b[95m 0.002155\u001b[0m | \u001b[95m 27.7    \u001b[0m | \u001b[95m 0.5354  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.857\n",
      "\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 8.8     \u001b[0m | \u001b[0m 0.7327  \u001b[0m | \u001b[0m 0.006509\u001b[0m | \u001b[0m 24.29   \u001b[0m | \u001b[0m 0.1788  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.884\n",
      "\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 8.8     \u001b[0m | \u001b[0m 0.6816  \u001b[0m | \u001b[0m 0.004632\u001b[0m | \u001b[0m 48.16   \u001b[0m | \u001b[0m 0.8388  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.762\n",
      "\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 8.7     \u001b[0m | \u001b[0m 0.1519  \u001b[0m | \u001b[0m 0.00639 \u001b[0m | \u001b[0m 22.08   \u001b[0m | \u001b[0m 0.883   \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.955\n",
      "\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 8.95    \u001b[0m | \u001b[0m 0.9444  \u001b[0m | \u001b[0m 0.004979\u001b[0m | \u001b[0m 21.5    \u001b[0m | \u001b[0m 0.1209  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.835\n",
      "\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 8.83    \u001b[0m | \u001b[0m 0.2201  \u001b[0m | \u001b[0m 0.003096\u001b[0m | \u001b[0m 31.94   \u001b[0m | \u001b[0m 0.3728  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.763\n",
      "\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 8.76    \u001b[0m | \u001b[0m 0.9633  \u001b[0m | \u001b[0m 0.008314\u001b[0m | \u001b[0m 46.71   \u001b[0m | \u001b[0m 0.7501  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.995\n",
      "\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 8.99    \u001b[0m | \u001b[0m 0.6078  \u001b[0m | \u001b[0m 0.003349\u001b[0m | \u001b[0m 24.46   \u001b[0m | \u001b[0m 0.4186  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.823\n",
      "\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 8.82    \u001b[0m | \u001b[0m 0.5215  \u001b[0m | \u001b[0m 0.009959\u001b[0m | \u001b[0m 24.49   \u001b[0m | \u001b[0m 0.1065  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.785\n",
      "\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 8.7     \u001b[0m | \u001b[0m 0.2334  \u001b[0m | \u001b[0m 0.007456\u001b[0m | \u001b[0m 44.61   \u001b[0m | \u001b[0m 0.2775  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.972\n",
      "\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 8.97    \u001b[0m | \u001b[0m 0.965   \u001b[0m | \u001b[0m 0.0088  \u001b[0m | \u001b[0m 31.17   \u001b[0m | \u001b[0m 0.4712  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.746\n",
      "\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 8.74    \u001b[0m | \u001b[0m 0.6817  \u001b[0m | \u001b[0m 0.001265\u001b[0m | \u001b[0m 39.41   \u001b[0m | \u001b[0m 0.2801  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.853\n",
      "\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 8.85    \u001b[0m | \u001b[0m 0.4655  \u001b[0m | \u001b[0m 0.008628\u001b[0m | \u001b[0m 12.26   \u001b[0m | \u001b[0m 0.596   \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.824\n",
      "\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 8.82    \u001b[0m | \u001b[0m 0.4297  \u001b[0m | \u001b[0m 0.003238\u001b[0m | \u001b[0m 34.77   \u001b[0m | \u001b[0m 0.6962  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.711\n",
      "\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 8.71    \u001b[0m | \u001b[0m 0.4389  \u001b[0m | \u001b[0m 0.006366\u001b[0m | \u001b[0m 20.51   \u001b[0m | \u001b[0m 0.5067  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.417\n",
      "\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 8.41    \u001b[0m | \u001b[0m 0.2287  \u001b[0m | \u001b[0m 0.003632\u001b[0m | \u001b[0m 44.11   \u001b[0m | \u001b[0m 0.1077  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.856\n",
      "\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 8.85    \u001b[0m | \u001b[0m 0.3454  \u001b[0m | \u001b[0m 0.008876\u001b[0m | \u001b[0m 17.74   \u001b[0m | \u001b[0m 0.6978  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.782\n",
      "\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 8.78    \u001b[0m | \u001b[0m 0.8821  \u001b[0m | \u001b[0m 0.008298\u001b[0m | \u001b[0m 14.6    \u001b[0m | \u001b[0m 0.677   \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.752\n",
      "\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 8.75    \u001b[0m | \u001b[0m 0.8558  \u001b[0m | \u001b[0m 0.006077\u001b[0m | \u001b[0m 11.64   \u001b[0m | \u001b[0m 0.4914  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.853\n",
      "\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 8.85    \u001b[0m | \u001b[0m 0.5021  \u001b[0m | \u001b[0m 0.007612\u001b[0m | \u001b[0m 40.11   \u001b[0m | \u001b[0m 0.4901  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.769\n",
      "\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 8.76    \u001b[0m | \u001b[0m 0.6006  \u001b[0m | \u001b[0m 0.006083\u001b[0m | \u001b[0m 48.4    \u001b[0m | \u001b[0m 0.552   \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.758\n",
      "\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 8.75    \u001b[0m | \u001b[0m 0.3734  \u001b[0m | \u001b[0m 0.008589\u001b[0m | \u001b[0m 44.65   \u001b[0m | \u001b[0m 0.7175  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.943\n",
      "\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 8.94    \u001b[0m | \u001b[0m 0.734   \u001b[0m | \u001b[0m 0.003312\u001b[0m | \u001b[0m 47.49   \u001b[0m | \u001b[0m 0.4942  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.817\n",
      "\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 8.8     \u001b[0m | \u001b[0m 0.872   \u001b[0m | \u001b[0m 0.004535\u001b[0m | \u001b[0m 20.74   \u001b[0m | \u001b[0m 0.3743  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.636\n",
      "\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 8.63    \u001b[0m | \u001b[0m 0.5769  \u001b[0m | \u001b[0m 0.00295 \u001b[0m | \u001b[0m 47.0    \u001b[0m | \u001b[0m 0.2556  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.838\n",
      "\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 8.83    \u001b[0m | \u001b[0m 0.1886  \u001b[0m | \u001b[0m 0.007526\u001b[0m | \u001b[0m 23.26   \u001b[0m | \u001b[0m 0.5555  \u001b[0m |\n",
      "Episode 7333/20000 || Best average reward 8.8756"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 20000/20000 || Best average reward 8.87\n",
      "\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 8.87    \u001b[0m | \u001b[0m 0.3583  \u001b[0m | \u001b[0m 0.004466\u001b[0m | \u001b[0m 21.45   \u001b[0m | \u001b[0m 0.5602  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.745\n",
      "\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 8.74    \u001b[0m | \u001b[0m 0.8678  \u001b[0m | \u001b[0m 0.008124\u001b[0m | \u001b[0m 27.66   \u001b[0m | \u001b[0m 0.5695  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.767\n",
      "\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 8.76    \u001b[0m | \u001b[0m 0.7423  \u001b[0m | \u001b[0m 0.002312\u001b[0m | \u001b[0m 47.47   \u001b[0m | \u001b[0m 0.5137  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.866\n",
      "\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 8.86    \u001b[0m | \u001b[0m 0.3706  \u001b[0m | \u001b[0m 0.007875\u001b[0m | \u001b[0m 40.91   \u001b[0m | \u001b[0m 0.6772  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.685\n",
      "\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 8.68    \u001b[0m | \u001b[0m 0.1152  \u001b[0m | \u001b[0m 0.009541\u001b[0m | \u001b[0m 31.02   \u001b[0m | \u001b[0m 0.3727  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.678\n",
      "\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 8.67    \u001b[0m | \u001b[0m 0.984   \u001b[0m | \u001b[0m 0.004037\u001b[0m | \u001b[0m 39.46   \u001b[0m | \u001b[0m 0.1238  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.943\n",
      "\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 8.94    \u001b[0m | \u001b[0m 0.2036  \u001b[0m | \u001b[0m 0.005185\u001b[0m | \u001b[0m 22.8    \u001b[0m | \u001b[0m 0.1404  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.776\n",
      "\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 8.77    \u001b[0m | \u001b[0m 0.6961  \u001b[0m | \u001b[0m 0.00655 \u001b[0m | \u001b[0m 37.19   \u001b[0m | \u001b[0m 0.1665  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 9.053\n",
      "\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 9.05    \u001b[0m | \u001b[0m 0.9322  \u001b[0m | \u001b[0m 0.001558\u001b[0m | \u001b[0m 49.49   \u001b[0m | \u001b[0m 0.4838  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.917\n",
      "\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 8.91    \u001b[0m | \u001b[0m 0.2228  \u001b[0m | \u001b[0m 0.001558\u001b[0m | \u001b[0m 4.31    \u001b[0m | \u001b[0m 0.3447  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.771\n",
      "\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 8.77    \u001b[0m | \u001b[0m 0.6523  \u001b[0m | \u001b[0m 0.001765\u001b[0m | \u001b[0m 2.816   \u001b[0m | \u001b[0m 0.2813  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.815\n",
      "\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 8.81    \u001b[0m | \u001b[0m 0.1625  \u001b[0m | \u001b[0m 0.001043\u001b[0m | \u001b[0m 27.53   \u001b[0m | \u001b[0m 0.3093  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.875\n",
      "\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 8.87    \u001b[0m | \u001b[0m 0.6424  \u001b[0m | \u001b[0m 0.007014\u001b[0m | \u001b[0m 16.73   \u001b[0m | \u001b[0m 0.3479  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.714\n",
      "\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 8.71    \u001b[0m | \u001b[0m 0.2659  \u001b[0m | \u001b[0m 0.006455\u001b[0m | \u001b[0m 17.05   \u001b[0m | \u001b[0m 0.6897  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.966\n",
      "\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 8.96    \u001b[0m | \u001b[0m 0.3426  \u001b[0m | \u001b[0m 0.005005\u001b[0m | \u001b[0m 26.64   \u001b[0m | \u001b[0m 0.9562  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.713\n",
      "\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 8.71    \u001b[0m | \u001b[0m 0.8605  \u001b[0m | \u001b[0m 0.005808\u001b[0m | \u001b[0m 6.769   \u001b[0m | \u001b[0m 0.8268  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.726\n",
      "\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 8.7     \u001b[0m | \u001b[0m 0.4597  \u001b[0m | \u001b[0m 0.001884\u001b[0m | \u001b[0m 11.36   \u001b[0m | \u001b[0m 0.6185  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.837\n",
      "\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 8.83    \u001b[0m | \u001b[0m 0.3162  \u001b[0m | \u001b[0m 0.006934\u001b[0m | \u001b[0m 41.07   \u001b[0m | \u001b[0m 0.9201  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward -60.32\n",
      "\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m-60.32   \u001b[0m | \u001b[0m 0.104   \u001b[0m | \u001b[0m 0.008462\u001b[0m | \u001b[0m 29.08   \u001b[0m | \u001b[0m 0.111   \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.945\n",
      "\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 8.94    \u001b[0m | \u001b[0m 0.9793  \u001b[0m | \u001b[0m 0.005596\u001b[0m | \u001b[0m 30.23   \u001b[0m | \u001b[0m 0.7832  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.718\n",
      "\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 8.71    \u001b[0m | \u001b[0m 0.6574  \u001b[0m | \u001b[0m 0.009021\u001b[0m | \u001b[0m 1.009   \u001b[0m | \u001b[0m 0.9845  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.952\n",
      "\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 8.95    \u001b[0m | \u001b[0m 0.9776  \u001b[0m | \u001b[0m 0.001149\u001b[0m | \u001b[0m 42.48   \u001b[0m | \u001b[0m 0.3844  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.717\n",
      "\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 8.71    \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 9.818   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 9.059\n",
      "\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 9.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 38.19   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.768\n",
      "\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 8.76    \u001b[0m | \u001b[0m 0.9684  \u001b[0m | \u001b[0m 0.009914\u001b[0m | \u001b[0m 19.03   \u001b[0m | \u001b[0m 0.1341  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.859\n",
      "\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 8.85    \u001b[0m | \u001b[0m 0.1309  \u001b[0m | \u001b[0m 0.005036\u001b[0m | \u001b[0m 9.845   \u001b[0m | \u001b[0m 0.9728  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward -65.14\n",
      "\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m-65.14   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 7.582   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward -6.35\n",
      "\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m-6.35    \u001b[0m | \u001b[0m 0.1479  \u001b[0m | \u001b[0m 0.004332\u001b[0m | \u001b[0m 1.59    \u001b[0m | \u001b[0m 0.1256  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.847\n",
      "\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 8.84    \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 9.238   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.775\n",
      "\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 8.7     \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 36.01   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.788\n",
      "\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 8.78    \u001b[0m | \u001b[0m 0.1327  \u001b[0m | \u001b[0m 0.001846\u001b[0m | \u001b[0m 19.12   \u001b[0m | \u001b[0m 0.9854  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.799\n",
      "\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 8.79    \u001b[0m | \u001b[0m 0.1049  \u001b[0m | \u001b[0m 0.005378\u001b[0m | \u001b[0m 45.85   \u001b[0m | \u001b[0m 0.9005  \u001b[0m |\n",
      "Episode 16572/20000 || Best average reward 8.864"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 20000/20000 || Best average reward 8.86\n",
      "\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 8.86    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 42.53   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.769\n",
      "\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 8.76    \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 29.31   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.855\n",
      "\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 8.85    \u001b[0m | \u001b[0m 0.9891  \u001b[0m | \u001b[0m 0.004873\u001b[0m | \u001b[0m 45.38   \u001b[0m | \u001b[0m 0.2094  \u001b[0m |\n",
      "Episode 10141/20000 || Best average reward 8.567"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 20000/20000 || Best average reward 8.66\n",
      "\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 8.66    \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 15.83   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward -64.49\n",
      "\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m-64.49   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 35.58   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.755\n",
      "\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 8.75    \u001b[0m | \u001b[0m 0.9837  \u001b[0m | \u001b[0m 0.004124\u001b[0m | \u001b[0m 33.9    \u001b[0m | \u001b[0m 0.9352  \u001b[0m |\n",
      "Episode 17698/20000 || Best average reward 8.765"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 20000/20000 || Best average reward 8.76\n",
      "\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 8.76    \u001b[0m | \u001b[0m 0.1194  \u001b[0m | \u001b[0m 0.00485 \u001b[0m | \u001b[0m 37.24   \u001b[0m | \u001b[0m 0.9807  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.815\n",
      "\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 8.81    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.704   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.857\n",
      "\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 8.85    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 25.43   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 6.367\n",
      "\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 6.36    \u001b[0m | \u001b[0m 0.1505  \u001b[0m | \u001b[0m 0.009881\u001b[0m | \u001b[0m 41.9    \u001b[0m | \u001b[0m 0.1215  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward -73.91\n",
      "\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m-73.9    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 15.78   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.897\n",
      "\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 8.89    \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 16.85   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Episode 4886/20000 || Best average reward 8.5577"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 20000/20000 || Best average reward 8.67\n",
      "\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 8.67    \u001b[0m | \u001b[0m 0.1054  \u001b[0m | \u001b[0m 0.003871\u001b[0m | \u001b[0m 13.43   \u001b[0m | \u001b[0m 0.9945  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.824\n",
      "\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 8.82    \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 38.32   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.633\n",
      "\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 8.63    \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 10.56   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward -78.89\n",
      "\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m-78.8    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 10.51   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.798\n",
      "\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 8.7     \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 2.208   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.787\n",
      "\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 8.78    \u001b[0m | \u001b[0m 0.9826  \u001b[0m | \u001b[0m 0.003514\u001b[0m | \u001b[0m 22.43   \u001b[0m | \u001b[0m 0.8942  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.943\n",
      "\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 8.94    \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 43.5    \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.951\n",
      "\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 8.95    \u001b[0m | \u001b[0m 0.9741  \u001b[0m | \u001b[0m 0.002346\u001b[0m | \u001b[0m 39.06   \u001b[0m | \u001b[0m 0.9955  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.766\n",
      "\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m 8.7     \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 37.64   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.762\n",
      "\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m 8.76    \u001b[0m | \u001b[0m 0.117   \u001b[0m | \u001b[0m 0.007675\u001b[0m | \u001b[0m 33.36   \u001b[0m | \u001b[0m 0.9456  \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward -91.22\n",
      "\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m-91.22   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 19.58   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "Episode 20000/20000 || Best average reward 8.698\n",
      "\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m 8.69    \u001b[0m | \u001b[0m 0.9139  \u001b[0m | \u001b[0m 0.009609\u001b[0m | \u001b[0m 18.67   \u001b[0m | \u001b[0m 0.8507  \u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "pbounds = {'epsilon': (0.001, 0.01), 'epsilon_divisor' : (1, 50), 'alpha': (0.1, 0.99), 'gamma': (0.1, 1.0)}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=interact_wrapper,\n",
    "    pbounds=pbounds,\n",
    "    random_state=47\n",
    ")\n",
    "\n",
    "optimizer.probe(\n",
    "    params={'epsilon': 0.01, 'epsilon_divisor' : 5, 'alpha': 0.9, 'gamma': 0.9},\n",
    "    lazy=True,\n",
    ")\n",
    "\n",
    "optimizer.maximize(\n",
    "    init_points=5,\n",
    "    n_iter=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep_rl]",
   "language": "python",
   "name": "conda-env-deep_rl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
